#!/usr/bin/env python3
"""
å¼ºåˆ¶CPUè®­ç»ƒä½†ä¿æŒGPUæ¶æ„çš„æ‰©æ•£æ¨¡å‹
ä¸“é—¨è§£å†³RTX 5090å…¼å®¹æ€§é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import os
import numpy as np
import time
import warnings

def force_cpu_with_gpu_architecture():
    """å¼ºåˆ¶ä½¿ç”¨CPUä½†ä¿æŒGPUæ¶æ„è®¾è®¡"""
    print("ğŸ”§ å¼ºåˆ¶CPUæ¨¡å¼ï¼ˆGPUæ¶æ„è®¾è®¡ï¼‰")
    
    # æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"ğŸ® æ£€æµ‹åˆ°GPU: {gpu_name}")
        
        if "RTX 5090" in gpu_name:
            print("âš ï¸ RTX 5090æ£€æµ‹åˆ°å…¼å®¹æ€§é—®é¢˜")
            print("ğŸ”„ å¼ºåˆ¶ä½¿ç”¨CPUé¿å…å…¼å®¹æ€§é—®é¢˜")
        else:
            print("ğŸ”„ ä¸ºäº†ç¨³å®šæ€§ï¼Œå¼ºåˆ¶ä½¿ç”¨CPU")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPU")
    
    # å¼ºåˆ¶ä½¿ç”¨CPU
    device = torch.device('cpu')
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
    
    return device

class SuperResolutionDataset(Dataset):
    """è¶…åˆ†è¾¨ç‡æ•°æ®é›†"""
    def __init__(self, size=50):
        self.size = size
        print(f"ğŸ“ åˆ›å»ºè¶…åˆ†è¾¨ç‡æ•°æ®é›†: {size} ä¸ªæ ·æœ¬")
    
    def __len__(self):
        return self.size
    
    def __getitem__(self, idx):
        # ç”ŸæˆLRå’ŒHRå›¾åƒå¯¹
        lr = torch.randn(3, 32, 32) * 0.3 + 0.5  # 32x32 LR
        hr = torch.randn(3, 128, 128) * 0.3 + 0.5  # 128x128 HR (4x)
        return torch.clamp(lr, 0, 1), torch.clamp(hr, 0, 1)

class DiffusionUNet(nn.Module):
    """æ‰©æ•£æ¨¡å‹çš„U-Netæ¶æ„ï¼ˆCPUä¼˜åŒ–ï¼‰"""
    def __init__(self, in_channels=3, out_channels=3):
        super().__init__()
        
        # ç¼–ç å™¨
        self.enc1 = self._conv_block(in_channels, 32)
        self.enc2 = self._conv_block(32, 64)
        self.enc3 = self._conv_block(64, 128)
        
        # ç“¶é¢ˆå±‚
        self.bottleneck = self._conv_block(128, 256)
        
        # è§£ç å™¨
        self.dec3 = self._conv_block(256 + 128, 128)
        self.dec2 = self._conv_block(128 + 64, 64)
        self.dec1 = self._conv_block(64 + 32, 32)
        
        # è¾“å‡ºå±‚
        self.final = nn.Conv2d(32, out_channels, 1)
        self.sigmoid = nn.Sigmoid()
        
    def _conv_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # ä¸Šé‡‡æ ·è¾“å…¥åˆ°ç›®æ ‡å°ºå¯¸
        x = nn.functional.interpolate(x, scale_factor=4, mode='bilinear', align_corners=False)
        
        # ç¼–ç è·¯å¾„
        e1 = self.enc1(x)
        e2 = self.enc2(nn.functional.max_pool2d(e1, 2))
        e3 = self.enc3(nn.functional.max_pool2d(e2, 2))
        
        # ç“¶é¢ˆ
        b = self.bottleneck(nn.functional.max_pool2d(e3, 2))
        
        # è§£ç è·¯å¾„
        d3 = nn.functional.interpolate(b, scale_factor=2, mode='bilinear', align_corners=False)
        d3 = self.dec3(torch.cat([d3, e3], dim=1))
        
        d2 = nn.functional.interpolate(d3, scale_factor=2, mode='bilinear', align_corners=False)
        d2 = self.dec2(torch.cat([d2, e2], dim=1))
        
        d1 = nn.functional.interpolate(d2, scale_factor=2, mode='bilinear', align_corners=False)
        d1 = self.dec1(torch.cat([d1, e1], dim=1))
        
        # è¾“å‡º
        output = self.final(d1)
        return self.sigmoid(output)

def add_noise_diffusion(images, timesteps, max_timesteps=1000):
    """æ·»åŠ æ‰©æ•£å™ªå£°"""
    # ç®€åŒ–çš„å™ªå£°è°ƒåº¦
    betas = torch.linspace(0.0001, 0.02, max_timesteps)
    alphas = 1.0 - betas
    alpha_cumprod = torch.cumprod(alphas, dim=0)
    
    # è·å–å½“å‰æ—¶é—´æ­¥çš„alpha
    alpha_t = alpha_cumprod[timesteps]
    
    # ç”Ÿæˆå™ªå£°
    noise = torch.randn_like(images)
    
    # æ·»åŠ å™ªå£°
    sqrt_alpha_t = torch.sqrt(alpha_t).view(-1, 1, 1, 1)
    sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t).view(-1, 1, 1, 1)
    
    noisy_images = sqrt_alpha_t * images + sqrt_one_minus_alpha_t * noise
    
    return noisy_images, noise

def train_epoch(model, dataloader, optimizer, criterion, device, epoch, max_timesteps=1000):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    count = 0
    
    print(f"Epoch {epoch} å¼€å§‹è®­ç»ƒ...")
    
    for batch_idx, (lr, hr) in enumerate(dataloader):
        try:
            # ç§»åŠ¨åˆ°è®¾å¤‡
            lr = lr.to(device)
            hr = hr.to(device)
            
            # éšæœºæ—¶é—´æ­¥
            timesteps = torch.randint(0, max_timesteps, (lr.size(0),))
            
            # æ·»åŠ å™ªå£°
            noisy_hr, noise = add_noise_diffusion(hr, timesteps, max_timesteps)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            
            # æ¨¡å‹é¢„æµ‹å™ªå£°
            predicted_noise = model(lr)
            
            # è®¡ç®—æŸå¤±ï¼ˆé¢„æµ‹å™ªå£° vs çœŸå®å™ªå£°ï¼‰
            loss = criterion(predicted_noise, noise)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            count += 1
            
            # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡
            if batch_idx % 10 == 0:
                print(f"  Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.6f}")
                
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ {batch_idx} å¤±è´¥: {e}")
            continue
    
    avg_loss = total_loss / count if count > 0 else 0
    print(f"Epoch {epoch} å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
    return avg_loss

def main():
    print("ğŸš€ å¼ºåˆ¶CPUæ‰©æ•£æ¨¡å‹è®­ç»ƒï¼ˆGPUæ¶æ„ï¼‰")
    print("=" * 50)
    
    # å¿½ç•¥è­¦å‘Š
    warnings.filterwarnings("ignore")
    
    # å¼ºåˆ¶ä½¿ç”¨CPU
    device = force_cpu_with_gpu_architecture()
    
    # è®­ç»ƒé…ç½®
    config = {
        'epochs': 5,
        'batch_size': 4,
        'learning_rate': 1e-4,
        'num_samples': 100,
        'max_timesteps': 1000
    }
    
    print("\nè®­ç»ƒé…ç½®:")
    for k, v in config.items():
        print(f"  {k}: {v}")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = SuperResolutionDataset(config['num_samples'])
    dataloader = DataLoader(
        dataset, 
        batch_size=config['batch_size'], 
        shuffle=True,
        num_workers=0
    )
    
    print(f"æ‰¹æ¬¡æ•°: {len(dataloader)}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ§  åˆ›å»ºæ‰©æ•£U-Netæ¨¡å‹...")
    model = DiffusionUNet().to(device)
    
    # å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ€»å‚æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±
    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])
    criterion = nn.MSELoss()
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])
    
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ ({config['epochs']} epochs)...")
    print("=" * 30)
    
    history = []
    
    try:
        for epoch in range(1, config['epochs'] + 1):
            start_time = time.time()
            
            # è®­ç»ƒ
            loss = train_epoch(model, dataloader, optimizer, criterion, device, epoch, config['max_timesteps'])
            history.append(loss)
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            epoch_time = time.time() - start_time
            print(f"Epoch {epoch} ç”¨æ—¶: {epoch_time:.2f}ç§’")
            print(f"å½“å‰å­¦ä¹ ç‡: {scheduler.get_last_lr()[0]:.6f}")
            print("-" * 30)
        
        print("\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ç»ˆæŸå¤±: {history[-1]:.6f}")
        
        # ä¿å­˜æ¨¡å‹
        model_path = "cpu_diffusion_model.pth"
        torch.save({
            'model_state_dict': model.state_dict(),
            'config': config,
            'history': history
        }, model_path)
        print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜åˆ°: {model_path}")
        
        # æµ‹è¯•
        print("\nğŸ§ª æ¨¡å‹æµ‹è¯•...")
        model.eval()
        with torch.no_grad():
            test_lr = torch.randn(1, 3, 32, 32).to(device)
            test_output = model(test_lr)
            print(f"è¾“å…¥: {test_lr.shape} -> è¾“å‡º: {test_output.shape}")
            print("âœ… æµ‹è¯•é€šè¿‡!")
            
    except Exception as e:
        print(f"âŒ è®­ç»ƒé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    return model, history

if __name__ == "__main__":
    model, history = main()