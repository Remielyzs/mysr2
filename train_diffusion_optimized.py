#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„æ‰©æ•£æ¨¡å‹è®­ç»ƒè„šæœ¬
åŸºäºç¯å¢ƒæµ‹è¯•ç»“æœè¿›è¡Œä¼˜åŒ–
"""

import os
import sys
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from pathlib import Path
import numpy as np
from PIL import Image

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from models.diffusion_sr import DiffusionSRModel

class SimpleSRDataset:
    """ç®€åŒ–çš„è¶…åˆ†è¾¨ç‡æ•°æ®é›†"""
    
    def __init__(self, lr_dir, hr_dir, patch_size=64):
        self.lr_dir = Path(lr_dir)
        self.hr_dir = Path(hr_dir)
        self.patch_size = patch_size
        
        # è·å–æ–‡ä»¶åˆ—è¡¨
        self.lr_files = sorted(list(self.lr_dir.glob('*.png')))
        self.hr_files = sorted(list(self.hr_dir.glob('*.png')))
        
        # ç¡®ä¿æ–‡ä»¶æ•°é‡åŒ¹é…
        assert len(self.lr_files) == len(self.hr_files), f"LRå’ŒHRæ–‡ä»¶æ•°é‡ä¸åŒ¹é…: {len(self.lr_files)} vs {len(self.hr_files)}"
        
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆ: {len(self.lr_files)} ä¸ªå›¾åƒå¯¹")
    
    def __len__(self):
        return len(self.lr_files)
    
    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        lr_path = self.lr_files[idx]
        hr_path = self.hr_files[idx]
        
        lr_image = Image.open(lr_path).convert('RGB')
        hr_image = Image.open(hr_path).convert('RGB')
        
        # è°ƒæ•´å¤§å°
        lr_image = lr_image.resize((self.patch_size, self.patch_size), Image.BICUBIC)
        hr_image = hr_image.resize((self.patch_size * 4, self.patch_size * 4), Image.BICUBIC)
        
        # è½¬æ¢ä¸ºtensor
        lr_tensor = torch.from_numpy(np.array(lr_image)).permute(2, 0, 1).float() / 255.0
        hr_tensor = torch.from_numpy(np.array(hr_image)).permute(2, 0, 1).float() / 255.0
        
        return lr_tensor, hr_tensor

def add_noise(hr_image, timestep, num_timesteps=1000):
    """æ·»åŠ å™ªå£°åˆ°é«˜åˆ†è¾¨ç‡å›¾åƒ"""
    # å®šä¹‰å™ªå£°è°ƒåº¦å‚æ•°
    beta_start = 0.0001
    beta_end = 0.02
    
    # è®¡ç®—betaå€¼
    betas = torch.linspace(beta_start, beta_end, num_timesteps)
    alphas = 1.0 - betas
    alpha_cumprod = torch.cumprod(alphas, dim=0)
    
    # ç¡®ä¿timestepåœ¨æœ‰æ•ˆèŒƒå›´å†…
    timestep = torch.clamp(torch.tensor(timestep), 0, num_timesteps - 1).long()
    
    # è·å–å½“å‰æ—¶é—´æ­¥çš„alpha_cumprodå€¼
    alpha_t = alpha_cumprod[timestep].to(hr_image.device)
    
    # ç”Ÿæˆå™ªå£°
    noise = torch.randn_like(hr_image)
    
    # æ·»åŠ å™ªå£° - ç¡®ä¿æ‰€æœ‰æ“ä½œéƒ½åœ¨tensorä¸Šè¿›è¡Œ
    sqrt_alpha_t = torch.sqrt(alpha_t)
    sqrt_one_minus_alpha_t = torch.sqrt(1.0 - alpha_t)
    
    # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…å›¾åƒå¼ é‡
    while len(sqrt_alpha_t.shape) < len(hr_image.shape):
        sqrt_alpha_t = sqrt_alpha_t.unsqueeze(-1)
        sqrt_one_minus_alpha_t = sqrt_one_minus_alpha_t.unsqueeze(-1)
    
    noisy_hr = sqrt_alpha_t * hr_image + sqrt_one_minus_alpha_t * noise
    
    return noisy_hr, noise

def train_epoch(model, dataloader, optimizer, criterion, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0.0
    num_batches = len(dataloader)
    
    print(f"\nEpoch {epoch + 1} å¼€å§‹è®­ç»ƒ...")
    
    for batch_idx, (lr_images, hr_images) in enumerate(dataloader):
        lr_images = lr_images.to(device)
        hr_images = hr_images.to(device)
        
        batch_size = lr_images.size(0)
        
        # éšæœºé‡‡æ ·æ—¶é—´æ­¥é•¿
        timesteps = torch.randint(0, 1000, (batch_size,)).float().to(device)
        
        # ä¸ºæ¯ä¸ªæ ·æœ¬æ·»åŠ å™ªå£°
        noisy_hr_list = []
        noise_list = []
        
        for i in range(batch_size):
            noisy_hr, noise = add_noise(hr_images[i:i+1], timesteps[i].item())
            noisy_hr_list.append(noisy_hr)
            noise_list.append(noise)
        
        noisy_hr_batch = torch.cat(noisy_hr_list, dim=0)
        noise_batch = torch.cat(noise_list, dim=0)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        predicted_noise = model.forward_with_noisy_hr(lr_images, noisy_hr_batch, timesteps)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(predicted_noise, noise_batch)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        total_loss += loss.item()
        
        # æ‰“å°è¿›åº¦
        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == num_batches:
            avg_loss = total_loss / (batch_idx + 1)
            print(f"  Batch {batch_idx + 1}/{num_batches}, Loss: {loss.item():.6f}, Avg Loss: {avg_loss:.6f}")
    
    avg_loss = total_loss / num_batches
    print(f"Epoch {epoch + 1} å®Œæˆ, å¹³å‡æŸå¤±: {avg_loss:.6f}")
    
    return avg_loss

def validate(model, dataloader, criterion, device):
    """éªŒè¯æ¨¡å‹"""
    model.eval()
    total_loss = 0.0
    num_batches = len(dataloader)
    
    print("å¼€å§‹éªŒè¯...")
    
    with torch.no_grad():
        for batch_idx, (lr_images, hr_images) in enumerate(dataloader):
            lr_images = lr_images.to(device)
            hr_images = hr_images.to(device)
            
            batch_size = lr_images.size(0)
            
            # ä½¿ç”¨å›ºå®šçš„æ—¶é—´æ­¥é•¿è¿›è¡ŒéªŒè¯
            timesteps = torch.full((batch_size,), 500.0).to(device)
            
            # æ·»åŠ å™ªå£°
            noisy_hr_list = []
            noise_list = []
            
            for i in range(batch_size):
                noisy_hr, noise = add_noise(hr_images[i:i+1], timesteps[i].item())
                noisy_hr_list.append(noisy_hr)
                noise_list.append(noise)
            
            noisy_hr_batch = torch.cat(noisy_hr_list, dim=0)
            noise_batch = torch.cat(noise_list, dim=0)
            
            # å‰å‘ä¼ æ’­
            predicted_noise = model.forward_with_noisy_hr(lr_images, noisy_hr_batch, timesteps)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(predicted_noise, noise_batch)
            total_loss += loss.item()
    
    avg_loss = total_loss / num_batches
    print(f"éªŒè¯å®Œæˆ, å¹³å‡æŸå¤±: {avg_loss:.6f}")
    
    return avg_loss

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ‰©æ•£æ¨¡å‹è¶…åˆ†è¾¨ç‡è®­ç»ƒ")
    print("=" * 60)
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # è®­ç»ƒé…ç½®
    config = {
        'scale_factor': 4,
        'num_timesteps': 1000,
        'unet_channels': [32, 64],  # é€‚ä¸­çš„é€šé“æ•°
        'attention_resolutions': [],  # ç¦ç”¨æ³¨æ„åŠ›ä»¥èŠ‚çœå†…å­˜
        'num_res_blocks': 1,
        'dropout': 0.0
    }
    
    # è®­ç»ƒå‚æ•°
    epochs = 3  # å‡å°‘epochæ•°ä»¥å¿«é€Ÿæµ‹è¯•
    batch_size = 2  # å°æ‰¹æ¬¡å¤§å°ä»¥é€‚åº”GPUå†…å­˜
    learning_rate = 1e-4
    patch_size = 32  # å°patchä»¥èŠ‚çœå†…å­˜
    
    print(f"è®­ç»ƒé…ç½®:")
    print(f"  Epochs: {epochs}")
    print(f"  Batch Size: {batch_size}")
    print(f"  Learning Rate: {learning_rate}")
    print(f"  Patch Size: {patch_size}")
    
    # åˆ›å»ºæ•°æ®é›†
    print("\nğŸ“ åŠ è½½æ•°æ®é›†...")
    train_dataset = SimpleSRDataset(
        'data/split_sample/train/lr',
        'data/split_sample/train/hr',
        patch_size=patch_size
    )
    
    val_dataset = SimpleSRDataset(
        'data/split_sample/val/lr',
        'data/split_sample/val/hr',
        patch_size=patch_size
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,  # Windowsä¸Šè®¾ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
        pin_memory=True if torch.cuda.is_available() else False
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True if torch.cuda.is_available() else False
    )
    
    print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ§  åˆ›å»ºæ¨¡å‹...")
    model = DiffusionSRModel(config).to(device)
    
    # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-2)
    criterion = nn.MSELoss()
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    print(f"ä¼˜åŒ–å™¨: AdamW")
    print(f"æŸå¤±å‡½æ•°: MSE Loss")
    print(f"å­¦ä¹ ç‡è°ƒåº¦: Cosine Annealing")
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = Path('results/diffusion_training')
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # è®­ç»ƒå¾ªç¯
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ ({epochs} epochs)...")
    print("=" * 60)
    
    best_val_loss = float('inf')
    train_losses = []
    val_losses = []
    
    start_time = time.time()
    
    for epoch in range(epochs):
        epoch_start_time = time.time()
        
        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, epoch)
        train_losses.append(train_loss)
        
        # éªŒè¯
        val_loss = validate(model, val_loader, criterion, device)
        val_losses.append(val_loss)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        current_lr = scheduler.get_last_lr()[0]
        
        epoch_time = time.time() - epoch_start_time
        
        print(f"\nEpoch {epoch + 1}/{epochs} æ€»ç»“:")
        print(f"  è®­ç»ƒæŸå¤±: {train_loss:.6f}")
        print(f"  éªŒè¯æŸå¤±: {val_loss:.6f}")
        print(f"  å­¦ä¹ ç‡: {current_lr:.2e}")
        print(f"  è€—æ—¶: {epoch_time:.1f}ç§’")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'train_loss': train_loss,
                'val_loss': val_loss,
                'config': config
            }
            torch.save(checkpoint, results_dir / 'best_model.pth')
            print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯æŸå¤±: {val_loss:.6f})")
        
        print("-" * 60)
    
    total_time = time.time() - start_time
    
    # è®­ç»ƒå®Œæˆ
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
    print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    print(f"æ¨¡å‹ä¿å­˜åœ¨: {results_dir / 'best_model.pth'}")
    
    # ä¿å­˜è®­ç»ƒå†å²
    import json
    history = {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'best_val_loss': best_val_loss,
        'total_time': total_time,
        'config': config
    }
    
    with open(results_dir / 'training_history.json', 'w') as f:
        json.dump(history, f, indent=2)
    
    print(f"è®­ç»ƒå†å²ä¿å­˜åœ¨: {results_dir / 'training_history.json'}")
    
    return model, history

if __name__ == '__main__':
    try:
        model, history = main()
        print("\nâœ… è®­ç»ƒæˆåŠŸå®Œæˆ!")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)