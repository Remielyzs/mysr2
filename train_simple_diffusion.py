#!/usr/bin/env python3
"""
ç®€åŒ–çš„æ‰©æ•£æ¨¡å‹è¶…åˆ†è¾¨ç‡è®­ç»ƒè„šæœ¬
ä¸“é—¨é’ˆå¯¹CUDAå…¼å®¹æ€§é—®é¢˜è¿›è¡Œä¼˜åŒ–
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import os
import numpy as np
import time
from pathlib import Path

# å¼ºåˆ¶ä½¿ç”¨CPUå¦‚æœCUDAä¸å…¼å®¹
def get_device():
    if torch.cuda.is_available():
        try:
            # æµ‹è¯•CUDAæ˜¯å¦çœŸæ­£å¯ç”¨
            test_tensor = torch.randn(1, device='cuda')
            del test_tensor
            return torch.device('cuda')
        except Exception as e:
            print(f"âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU: {e}")
            return torch.device('cpu')
    else:
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        return torch.device('cpu')

class SimpleSRDataset(Dataset):
    """ç®€åŒ–çš„è¶…åˆ†è¾¨ç‡æ•°æ®é›†"""
    def __init__(self, hr_dir, lr_dir, patch_size=64, max_samples=100):
        self.hr_dir = Path(hr_dir)
        self.lr_dir = Path(lr_dir)
        self.patch_size = patch_size
        
        # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
        hr_files = list(self.hr_dir.glob("*.png"))[:max_samples]
        lr_files = list(self.lr_dir.glob("*.png"))[:max_samples]
        
        # ç¡®ä¿HRå’ŒLRæ–‡ä»¶åŒ¹é…
        self.image_pairs = []
        for hr_file in hr_files:
            lr_file = self.lr_dir / hr_file.name
            if lr_file.exists():
                self.image_pairs.append((hr_file, lr_file))
        
        print(f"ğŸ“ æ‰¾åˆ° {len(self.image_pairs)} ä¸ªå›¾åƒå¯¹")
        
        # ç®€å•çš„å˜æ¢
        self.transform = transforms.Compose([
            transforms.ToTensor(),
        ])
    
    def __len__(self):
        return len(self.image_pairs)
    
    def __getitem__(self, idx):
        hr_path, lr_path = self.image_pairs[idx]
        
        try:
            # åŠ è½½å›¾åƒ
            hr_image = Image.open(hr_path).convert('RGB')
            lr_image = Image.open(lr_path).convert('RGB')
            
            # è°ƒæ•´å¤§å°
            hr_image = hr_image.resize((self.patch_size, self.patch_size), Image.LANCZOS)
            lr_image = lr_image.resize((self.patch_size // 4, self.patch_size // 4), Image.LANCZOS)
            
            # è½¬æ¢ä¸ºtensor
            hr_tensor = self.transform(hr_image)
            lr_tensor = self.transform(lr_image)
            
            return lr_tensor, hr_tensor
            
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾åƒå¤±è´¥ {hr_path}: {e}")
            # è¿”å›éšæœºæ•°æ®ä½œä¸ºfallback
            return torch.randn(3, self.patch_size // 4, self.patch_size // 4), torch.randn(3, self.patch_size, self.patch_size)

class SimpleUNet(nn.Module):
    """æç®€çš„U-Netæ¨¡å‹"""
    def __init__(self, in_channels=3, out_channels=3):
        super().__init__()
        
        # ç¼–ç å™¨
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        
        self.enc2 = nn.Sequential(
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        
        # è§£ç å™¨
        self.dec2 = nn.Sequential(
            nn.ConvTranspose2d(64, 32, 2, stride=2),
            nn.ReLU(inplace=True)
        )
        
        self.dec1 = nn.Sequential(
            nn.Conv2d(64, 32, 3, padding=1),  # 64 = 32 + 32 (skip connection)
            nn.ReLU(inplace=True),
            nn.Conv2d(32, out_channels, 3, padding=1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        # ä¸Šé‡‡æ ·è¾“å…¥
        x = nn.functional.interpolate(x, scale_factor=4, mode='bilinear', align_corners=False)
        
        # ç¼–ç 
        e1 = self.enc1(x)
        e2 = self.enc2(e1)
        
        # è§£ç 
        d2 = self.dec2(e2)
        d1 = self.dec1(torch.cat([d2, e1], dim=1))
        
        return d1

def add_simple_noise(image, noise_level=0.1):
    """æ·»åŠ ç®€å•çš„é«˜æ–¯å™ªå£°"""
    noise = torch.randn_like(image) * noise_level
    return torch.clamp(image + noise, 0, 1), noise

def train_epoch(model, dataloader, optimizer, criterion, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    num_batches = len(dataloader)
    
    print(f"Epoch {epoch} å¼€å§‹è®­ç»ƒ...")
    
    for batch_idx, (lr_images, hr_images) in enumerate(dataloader):
        try:
            lr_images = lr_images.to(device)
            hr_images = hr_images.to(device)
            
            # æ·»åŠ å™ªå£°ï¼ˆç®€åŒ–çš„æ‰©æ•£è¿‡ç¨‹ï¼‰
            noisy_hr, noise = add_simple_noise(hr_images)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            predicted = model(lr_images)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(predicted, hr_images)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 10 == 0:
                print(f"  Batch {batch_idx}/{num_batches}, Loss: {loss.item():.6f}")
                
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ {batch_idx} è®­ç»ƒå¤±è´¥: {e}")
            continue
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    print(f"Epoch {epoch} å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
    return avg_loss

def main():
    print("ğŸš€ å¼€å§‹ç®€åŒ–æ‰©æ•£æ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    # è®¾å¤‡æ£€æµ‹
    device = get_device()
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è®­ç»ƒé…ç½®
    config = {
        'epochs': 2,
        'batch_size': 1,  # å‡å°æ‰¹æ¬¡å¤§å°
        'learning_rate': 1e-4,
        'patch_size': 64,  # å‡å°patchå¤§å°
        'max_samples': 50  # é™åˆ¶æ ·æœ¬æ•°é‡
    }
    
    print("è®­ç»ƒé…ç½®:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    # æ•°æ®è·¯å¾„
    hr_dir = "data/DIV2K_train_HR"
    lr_dir = "data/DIV2K_train_LR_bicubic/X4"
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not os.path.exists(hr_dir) or not os.path.exists(lr_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {hr_dir} æˆ– {lr_dir}")
        print("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...")
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        class DummyDataset(Dataset):
            def __init__(self, size=20):
                self.size = size
            
            def __len__(self):
                return self.size
            
            def __getitem__(self, idx):
                lr = torch.randn(3, 16, 16)  # 16x16 LR
                hr = torch.randn(3, 64, 64)  # 64x64 HR
                return lr, hr
        
        train_dataset = DummyDataset(config['max_samples'])
        print(f"ğŸ“ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®é›†: {len(train_dataset)} ä¸ªæ ·æœ¬")
    else:
        # åŠ è½½çœŸå®æ•°æ®
        train_dataset = SimpleSRDataset(
            hr_dir, lr_dir, 
            patch_size=config['patch_size'],
            max_samples=config['max_samples']
        )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'], 
        shuffle=True,
        num_workers=0  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
    )
    
    print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ§  åˆ›å»ºæ¨¡å‹...")
    model = SimpleUNet().to(device)
    
    # è®¡ç®—å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])
    criterion = nn.MSELoss()
    
    print(f"ä¼˜åŒ–å™¨: Adam")
    print(f"æŸå¤±å‡½æ•°: MSE Loss")
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ ({config['epochs']} epochs)...")
    print("=" * 50)
    
    training_history = []
    
    try:
        for epoch in range(1, config['epochs'] + 1):
            start_time = time.time()
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss = train_epoch(model, train_loader, optimizer, criterion, device, epoch)
            
            epoch_time = time.time() - start_time
            training_history.append(train_loss)
            
            print(f"Epoch {epoch} å®Œæˆï¼Œç”¨æ—¶: {epoch_time:.2f}ç§’")
            print("-" * 30)
            
        print("\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ç»ˆæŸå¤±: {training_history[-1]:.6f}")
        
        # ä¿å­˜æ¨¡å‹
        model_path = "simple_diffusion_model.pth"
        torch.save({
            'model_state_dict': model.state_dict(),
            'config': config,
            'training_history': training_history
        }, model_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    return model, training_history

if __name__ == "__main__":
    model, history = main()