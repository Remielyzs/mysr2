#!/usr/bin/env python3
"""
åŸºäºStable Diffusionçš„LoRAå¾®è°ƒè®­ç»ƒè„šæœ¬
ä¸“é—¨ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡çš„LoRAå¾®è°ƒ
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import json
import time
from pathlib import Path
import warnings
from typing import Dict, List, Optional, Tuple
import logging

# å°è¯•å¯¼å…¥diffusersç›¸å…³åŒ…
try:
    from diffusers import StableDiffusionPipeline, UNet2DConditionModel, DDPMScheduler
    from diffusers.optimization import get_scheduler
    from transformers import CLIPTextModel, CLIPTokenizer
    DIFFUSERS_AVAILABLE = True
except ImportError:
    print("âš ï¸ diffusersåŒ…æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–å®ç°")
    DIFFUSERS_AVAILABLE = False

# å°è¯•å¯¼å…¥peft
try:
    from peft import LoraConfig, get_peft_model, TaskType
    PEFT_AVAILABLE = True
except ImportError:
    print("âš ï¸ peftåŒ…æœªå®‰è£…ï¼Œå°†ä½¿ç”¨è‡ªå®šä¹‰LoRAå®ç°")
    PEFT_AVAILABLE = False

def setup_gpu_for_lora():
    """è®¾ç½®GPUç¯å¢ƒç”¨äºLoRAè®­ç»ƒ"""
    print("ğŸ”§ è®¾ç½®GPUç¯å¢ƒ...")
    
    if not torch.cuda.is_available():
        raise RuntimeError("âŒ CUDAä¸å¯ç”¨ï¼LoRAå¾®è°ƒéœ€è¦GPUæ”¯æŒ")
    
    device = torch.device('cuda')
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    
    print(f"ğŸ® GPU: {gpu_name}")
    print(f"ğŸ’¾ GPUå†…å­˜: {gpu_memory:.1f} GB")
    
    # RTX 5090ç‰¹æ®Šå¤„ç†
    if "RTX 5090" in gpu_name:
        print("âš ï¸ æ£€æµ‹åˆ°RTX 5090ï¼Œåº”ç”¨å…¼å®¹æ€§è®¾ç½®...")
        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
        os.environ['TORCH_CUDA_ARCH_LIST'] = '8.0;8.6;8.9;9.0'
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cudnn.benchmark = True
    
    # æµ‹è¯•GPU
    try:
        test_tensor = torch.randn(2, 2, device=device)
        _ = test_tensor @ test_tensor
        del test_tensor
        torch.cuda.empty_cache()
        print("âœ… GPUæµ‹è¯•é€šè¿‡")
    except Exception as e:
        raise RuntimeError(f"âŒ GPUæµ‹è¯•å¤±è´¥: {e}")
    
    return device

class CustomLoRALayer(nn.Module):
    """è‡ªå®šä¹‰LoRAå±‚å®ç°"""
    def __init__(self, in_features: int, out_features: int, rank: int = 4, alpha: float = 1.0):
        super().__init__()
        self.rank = rank
        self.alpha = alpha
        self.scaling = alpha / rank
        
        # LoRAæƒé‡
        self.lora_A = nn.Parameter(torch.randn(rank, in_features) * 0.01)
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))
        
    def forward(self, x):
        return (x @ self.lora_A.T @ self.lora_B.T) * self.scaling

class LoRAConv2d(nn.Module):
    """LoRAå·ç§¯å±‚"""
    def __init__(self, conv_layer: nn.Conv2d, rank: int = 4, alpha: float = 1.0):
        super().__init__()
        self.conv = conv_layer
        self.rank = rank
        self.alpha = alpha
        self.scaling = alpha / rank
        
        # å†»ç»“åŸå§‹æƒé‡
        for param in self.conv.parameters():
            param.requires_grad = False
        
        # LoRAæƒé‡
        self.lora_down = nn.Conv2d(
            conv_layer.in_channels, rank, 1, bias=False
        )
        self.lora_up = nn.Conv2d(
            rank, conv_layer.out_channels, 1, bias=False
        )
        
        # åˆå§‹åŒ–
        nn.init.kaiming_uniform_(self.lora_down.weight)
        nn.init.zeros_(self.lora_up.weight)
        
    def forward(self, x):
        original_out = self.conv(x)
        lora_out = self.lora_up(self.lora_down(x)) * self.scaling
        return original_out + lora_out

class SimpleUNet(nn.Module):
    """ç®€åŒ–çš„U-Netæ¨¡å‹ç”¨äºè¶…åˆ†è¾¨ç‡"""
    def __init__(self, in_channels=3, out_channels=3, features=[64, 128, 256, 512]):
        super().__init__()
        self.features = features
        
        # ç¼–ç å™¨
        self.encoder = nn.ModuleList()
        self.pool = nn.MaxPool2d(2, 2)
        
        for feature in features:
            self.encoder.append(self._conv_block(in_channels, feature))
            in_channels = feature
        
        # ç“¶é¢ˆå±‚
        self.bottleneck = self._conv_block(features[-1], features[-1] * 2)
        
        # è§£ç å™¨
        self.decoder = nn.ModuleList()
        self.upconvs = nn.ModuleList()
        
        for feature in reversed(features):
            self.upconvs.append(nn.ConvTranspose2d(feature * 2, feature, 2, 2))
            self.decoder.append(self._conv_block(feature * 2, feature))
        
        # è¾“å‡ºå±‚
        self.final_conv = nn.Conv2d(features[0], out_channels, 1)
        
    def _conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # ç¼–ç è·¯å¾„
        skip_connections = []
        
        for encoder in self.encoder:
            x = encoder(x)
            skip_connections.append(x)
            x = self.pool(x)
        
        # ç“¶é¢ˆ
        x = self.bottleneck(x)
        
        # è§£ç è·¯å¾„
        skip_connections = skip_connections[::-1]
        
        for idx, (upconv, decoder) in enumerate(zip(self.upconvs, self.decoder)):
            x = upconv(x)
            skip_connection = skip_connections[idx]
            
            # å¤„ç†å°ºå¯¸ä¸åŒ¹é…
            if x.shape != skip_connection.shape:
                x = nn.functional.interpolate(x, size=skip_connection.shape[2:])
            
            concat_skip = torch.cat([skip_connection, x], dim=1)
            x = decoder(concat_skip)
        
        return torch.sigmoid(self.final_conv(x))

class LoRAUNet(nn.Module):
    """å¸¦LoRAçš„U-Netæ¨¡å‹"""
    def __init__(self, base_unet: SimpleUNet, lora_rank: int = 4, lora_alpha: float = 1.0):
        super().__init__()
        self.base_unet = base_unet
        self.lora_layers = nn.ModuleDict()
        
        # ä¸ºå…³é”®å·ç§¯å±‚æ·»åŠ LoRA
        self._add_lora_to_convs(lora_rank, lora_alpha)
        
    def _add_lora_to_convs(self, rank: int, alpha: float):
        """ä¸ºå·ç§¯å±‚æ·»åŠ LoRA"""
        # ç¼–ç å™¨LoRA
        for i, encoder_block in enumerate(self.base_unet.encoder):
            for j, layer in enumerate(encoder_block):
                if isinstance(layer, nn.Conv2d):
                    lora_name = f"encoder_{i}_conv_{j}"
                    self.lora_layers[lora_name] = LoRAConv2d(layer, rank, alpha)
        
        # è§£ç å™¨LoRA
        for i, decoder_block in enumerate(self.base_unet.decoder):
            for j, layer in enumerate(decoder_block):
                if isinstance(layer, nn.Conv2d):
                    lora_name = f"decoder_{i}_conv_{j}"
                    self.lora_layers[lora_name] = LoRAConv2d(layer, rank, alpha)
    
    def forward(self, x):
        return self.base_unet(x)
    
    def get_lora_parameters(self):
        """è·å–LoRAå‚æ•°"""
        lora_params = []
        for lora_layer in self.lora_layers.values():
            lora_params.extend(list(lora_layer.parameters()))
        return lora_params

class SRDataset(Dataset):
    """è¶…åˆ†è¾¨ç‡æ•°æ®é›†"""
    def __init__(self, data_dir: str, lr_size: int = 64, hr_size: int = 256, max_samples: int = None):
        self.data_dir = Path(data_dir)
        self.lr_size = lr_size
        self.hr_size = hr_size
        
        # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
        self.image_files = []
        if self.data_dir.exists():
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                self.image_files.extend(list(self.data_dir.glob(ext)))
        
        if not self.image_files:
            print(f"âš ï¸ åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            self.use_synthetic = True
            self.length = max_samples or 100
        else:
            self.use_synthetic = False
            if max_samples:
                self.image_files = self.image_files[:max_samples]
            self.length = len(self.image_files)
        
        # å˜æ¢
        self.lr_transform = transforms.Compose([
            transforms.Resize((lr_size, lr_size)),
            transforms.ToTensor(),
        ])
        
        self.hr_transform = transforms.Compose([
            transforms.Resize((hr_size, hr_size)),
            transforms.ToTensor(),
        ])
        
        print(f"ğŸ“ æ•°æ®é›†: {self.length} ä¸ªæ ·æœ¬")
        print(f"ğŸ“ LRå°ºå¯¸: {lr_size}x{lr_size}, HRå°ºå¯¸: {hr_size}x{hr_size}")
    
    def __len__(self):
        return self.length
    
    def __getitem__(self, idx):
        if self.use_synthetic:
            # ç”Ÿæˆåˆæˆæ•°æ®
            lr = torch.randn(3, self.lr_size, self.lr_size) * 0.3 + 0.5
            hr = torch.randn(3, self.hr_size, self.hr_size) * 0.3 + 0.5
            return torch.clamp(lr, 0, 1), torch.clamp(hr, 0, 1)
        else:
            # åŠ è½½çœŸå®å›¾åƒ
            img_path = self.image_files[idx]
            try:
                image = Image.open(img_path).convert('RGB')
                lr = self.lr_transform(image)
                hr = self.hr_transform(image)
                return lr, hr
            except Exception as e:
                print(f"âš ï¸ åŠ è½½å›¾åƒå¤±è´¥ {img_path}: {e}")
                # è¿”å›åˆæˆæ•°æ®ä½œä¸ºå¤‡ç”¨
                lr = torch.randn(3, self.lr_size, self.lr_size) * 0.3 + 0.5
                hr = torch.randn(3, self.hr_size, self.hr_size) * 0.3 + 0.5
                return torch.clamp(lr, 0, 1), torch.clamp(hr, 0, 1)

def train_epoch(model, dataloader, optimizer, criterion, device, epoch, total_epochs):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    num_batches = len(dataloader)
    
    print(f"\nEpoch {epoch}/{total_epochs} å¼€å§‹è®­ç»ƒ...")
    
    for batch_idx, (lr, hr) in enumerate(dataloader):
        try:
            # ç§»åŠ¨åˆ°GPU
            lr = lr.to(device, non_blocking=True)
            hr = hr.to(device, non_blocking=True)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            
            # ä¸Šé‡‡æ ·LRåˆ°HRå°ºå¯¸
            lr_upsampled = nn.functional.interpolate(
                lr, size=hr.shape[2:], mode='bilinear', align_corners=False
            )
            
            # æ¨¡å‹é¢„æµ‹
            pred_hr = model(lr_upsampled)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(pred_hr, hr)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 10 == 0:
                progress = 100.0 * batch_idx / num_batches
                print(f"  [{batch_idx:3d}/{num_batches:3d}] ({progress:5.1f}%) Loss: {loss.item():.6f}")
            
            # GPUå†…å­˜ç®¡ç†
            if batch_idx % 20 == 0:
                torch.cuda.empty_cache()
                
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ {batch_idx} å¤±è´¥: {e}")
            continue
    
    avg_loss = total_loss / num_batches
    print(f"Epoch {epoch} å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
    return avg_loss

def save_model_and_lora(model, optimizer, epoch, loss, save_dir):
    """ä¿å­˜æ¨¡å‹å’ŒLoRAæƒé‡"""
    save_dir = Path(save_dir)
    save_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜å®Œæ•´æ¨¡å‹
    model_path = save_dir / f"lora_model_epoch_{epoch}.pth"
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
    }, model_path)
    
    # å•ç‹¬ä¿å­˜LoRAæƒé‡
    if hasattr(model, 'lora_layers'):
        lora_path = save_dir / f"lora_weights_epoch_{epoch}.pth"
        lora_state = {}
        for name, lora_layer in model.lora_layers.items():
            lora_state[name] = lora_layer.state_dict()
        torch.save(lora_state, lora_path)
        print(f"ğŸ’¾ LoRAæƒé‡ä¿å­˜åˆ°: {lora_path}")
    
    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜åˆ°: {model_path}")
    return model_path, lora_path if hasattr(model, 'lora_layers') else None

def test_model(model, device, lr_size=64, hr_size=256):
    """æµ‹è¯•æ¨¡å‹"""
    print("\nğŸ§ª æ¨¡å‹æµ‹è¯•...")
    model.eval()
    
    with torch.no_grad():
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_lr = torch.randn(1, 3, lr_size, lr_size).to(device)
        
        # ä¸Šé‡‡æ ·åˆ°HRå°ºå¯¸
        test_lr_upsampled = nn.functional.interpolate(
            test_lr, size=(hr_size, hr_size), mode='bilinear', align_corners=False
        )
        
        # æ¨¡å‹æ¨ç†
        test_output = model(test_lr_upsampled)
        
        print(f"è¾“å…¥LR: {test_lr.shape}")
        print(f"ä¸Šé‡‡æ ·LR: {test_lr_upsampled.shape}")
        print(f"è¾“å‡ºHR: {test_output.shape}")
        print("âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡!")
        
        return test_output

def main():
    print("ğŸš€ åŸºäºStable Diffusionçš„LoRAå¾®è°ƒè®­ç»ƒ")
    print("=" * 60)
    
    # å¿½ç•¥è­¦å‘Š
    warnings.filterwarnings("ignore")
    
    # è®¾ç½®GPU
    device = setup_gpu_for_lora()
    
    # è®­ç»ƒé…ç½®
    config = {
        'epochs': 10,
        'batch_size': 4,
        'learning_rate': 1e-4,
        'lora_rank': 8,
        'lora_alpha': 16.0,
        'lr_size': 64,
        'hr_size': 256,
        'max_samples': 200,
        'data_dir': './data/images',  # å›¾åƒæ•°æ®ç›®å½•
        'save_dir': './lora_checkpoints'
    }
    
    print("\nğŸ“‹ è®­ç»ƒé…ç½®:")
    for k, v in config.items():
        print(f"  {k}: {v}")
    
    # åˆ›å»ºæ•°æ®é›†
    print(f"\nğŸ“ åˆ›å»ºæ•°æ®é›†...")
    dataset = SRDataset(
        data_dir=config['data_dir'],
        lr_size=config['lr_size'],
        hr_size=config['hr_size'],
        max_samples=config['max_samples']
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=0,  # Windowså…¼å®¹æ€§
        pin_memory=True
    )
    
    print(f"æ‰¹æ¬¡æ•°: {len(dataloader)}")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ§  åˆ›å»ºLoRA U-Netæ¨¡å‹...")
    base_unet = SimpleUNet(in_channels=3, out_channels=3)
    model = LoRAUNet(
        base_unet=base_unet,
        lora_rank=config['lora_rank'],
        lora_alpha=config['lora_alpha']
    ).to(device)
    
    # å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    lora_params = sum(p.numel() for p in model.get_lora_parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"æ€»å‚æ•°: {total_params:,}")
    print(f"LoRAå‚æ•°: {lora_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"LoRAå‚æ•°æ¯”ä¾‹: {lora_params/total_params*100:.2f}%")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.AdamW(
        model.get_lora_parameters(),  # åªè®­ç»ƒLoRAå‚æ•°
        lr=config['learning_rate'],
        weight_decay=1e-4
    )
    
    criterion = nn.MSELoss()
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=config['epochs']
    )
    
    print(f"\nğŸ¯ å¼€å§‹LoRAå¾®è°ƒè®­ç»ƒ...")
    print("=" * 40)
    
    # è®­ç»ƒå†å²
    history = []
    best_loss = float('inf')
    
    try:
        for epoch in range(1, config['epochs'] + 1):
            start_time = time.time()
            
            # è®­ç»ƒ
            avg_loss = train_epoch(
                model, dataloader, optimizer, criterion, device, epoch, config['epochs']
            )
            history.append(avg_loss)
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_loss < best_loss:
                best_loss = avg_loss
                save_model_and_lora(model, optimizer, epoch, avg_loss, config['save_dir'])
            
            epoch_time = time.time() - start_time
            current_lr = scheduler.get_last_lr()[0]
            
            print(f"Epoch {epoch} ç”¨æ—¶: {epoch_time:.2f}ç§’")
            print(f"å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}")
            print(f"æœ€ä½³æŸå¤±: {best_loss:.6f}")
            print("-" * 40)
            
            # GPUå†…å­˜æ¸…ç†
            torch.cuda.empty_cache()
        
        print("\nâœ… LoRAå¾®è°ƒè®­ç»ƒå®Œæˆ!")
        print(f"æœ€ç»ˆæŸå¤±: {history[-1]:.6f}")
        print(f"æœ€ä½³æŸå¤±: {best_loss:.6f}")
        
        # æœ€ç»ˆæµ‹è¯•
        test_model(model, device, config['lr_size'], config['hr_size'])
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = Path(config['save_dir']) / 'training_history.json'
        with open(history_path, 'w') as f:
            json.dump({
                'config': config,
                'history': history,
                'best_loss': best_loss
            }, f, indent=2)
        print(f"ğŸ“Š è®­ç»ƒå†å²ä¿å­˜åˆ°: {history_path}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        print("ğŸ§¹ GPUå†…å­˜å·²æ¸…ç†")

if __name__ == "__main__":
    main()