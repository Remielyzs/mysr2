#!/usr/bin/env python3
"""
GPUå…¼å®¹æ€§ä¿®æ­£ç‰ˆæœ¬çš„æ‰©æ•£æ¨¡å‹è¶…åˆ†è¾¨ç‡è®­ç»ƒè„šæœ¬
ä¸“é—¨é’ˆå¯¹RTX 5090çš„CUDAå…¼å®¹æ€§é—®é¢˜è¿›è¡Œä¼˜åŒ–
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import os
import numpy as np
import time
from pathlib import Path
import warnings

def setup_gpu_compatibility():
    """è®¾ç½®GPUå…¼å®¹æ€§ï¼Œå¤„ç†RTX 5090çš„CUDAæ¶æ„é—®é¢˜"""
    print("ğŸ”§ è®¾ç½®GPUå…¼å®¹æ€§...")
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        return torch.device('cpu')
    
    # è·å–GPUä¿¡æ¯
    gpu_name = torch.cuda.get_device_name(0)
    print(f"ğŸ® æ£€æµ‹åˆ°GPU: {gpu_name}")
    
    # é’ˆå¯¹RTX 5090çš„ç‰¹æ®Šå¤„ç†
    if "RTX 5090" in gpu_name or "RTX 50" in gpu_name:
        print("âš ï¸ æ£€æµ‹åˆ°RTX 5090ï¼Œåº”ç”¨å…¼å®¹æ€§ä¿®æ­£...")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥å¼ºåˆ¶å…¼å®¹æ€§
        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
        os.environ['TORCH_CUDA_ARCH_LIST'] = '8.0;8.6;8.9;9.0'
        
        # å°è¯•è®¾ç½®å…¼å®¹æ¨¡å¼
        try:
            # å¼ºåˆ¶ä½¿ç”¨è¾ƒä½çš„CUDAæ¶æ„è¿›è¡Œè®¡ç®—
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            
            # æµ‹è¯•GPUæ˜¯å¦çœŸæ­£å¯ç”¨
            test_tensor = torch.randn(10, 10, device='cuda')
            test_result = test_tensor @ test_tensor.T
            del test_tensor, test_result
            
            print("âœ… GPUå…¼å®¹æ€§ä¿®æ­£æˆåŠŸ")
            return torch.device('cuda')
            
        except Exception as e:
            print(f"âŒ GPUå…¼å®¹æ€§ä¿®æ­£å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°CPUæ¨¡å¼")
            return torch.device('cpu')
    
    else:
        # å…¶ä»–GPUçš„æ ‡å‡†å¤„ç†
        try:
            test_tensor = torch.randn(10, 10, device='cuda')
            del test_tensor
            print("âœ… GPUå¯ç”¨")
            return torch.device('cuda')
        except Exception as e:
            print(f"âŒ GPUæµ‹è¯•å¤±è´¥: {e}")
            return torch.device('cpu')

class OptimizedSRDataset(Dataset):
    """ä¼˜åŒ–çš„è¶…åˆ†è¾¨ç‡æ•°æ®é›†ï¼Œæ”¯æŒGPUè®­ç»ƒ"""
    def __init__(self, hr_dir=None, lr_dir=None, patch_size=64, max_samples=100, use_real_data=True):
        self.patch_size = patch_size
        self.use_real_data = use_real_data
        
        if use_real_data and hr_dir and lr_dir and os.path.exists(hr_dir) and os.path.exists(lr_dir):
            self.hr_dir = Path(hr_dir)
            self.lr_dir = Path(lr_dir)
            
            # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
            hr_files = list(self.hr_dir.glob("*.png"))[:max_samples]
            lr_files = list(self.lr_dir.glob("*.png"))[:max_samples]
            
            # ç¡®ä¿HRå’ŒLRæ–‡ä»¶åŒ¹é…
            self.image_pairs = []
            for hr_file in hr_files:
                lr_file = self.lr_dir / hr_file.name
                if lr_file.exists():
                    self.image_pairs.append((hr_file, lr_file))
            
            print(f"ğŸ“ æ‰¾åˆ° {len(self.image_pairs)} ä¸ªçœŸå®å›¾åƒå¯¹")
            self.data_size = len(self.image_pairs)
        else:
            print(f"ğŸ“ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®é›†: {max_samples} ä¸ªæ ·æœ¬")
            self.data_size = max_samples
            self.image_pairs = None
        
        # GPUä¼˜åŒ–çš„å˜æ¢
        self.transform = transforms.Compose([
            transforms.ToTensor(),
        ])
    
    def __len__(self):
        return self.data_size
    
    def __getitem__(self, idx):
        if self.use_real_data and self.image_pairs:
            return self._get_real_data(idx)
        else:
            return self._get_synthetic_data(idx)
    
    def _get_real_data(self, idx):
        """åŠ è½½çœŸå®æ•°æ®"""
        hr_path, lr_path = self.image_pairs[idx]
        
        try:
            # åŠ è½½å›¾åƒ
            hr_image = Image.open(hr_path).convert('RGB')
            lr_image = Image.open(lr_path).convert('RGB')
            
            # è°ƒæ•´å¤§å°
            hr_image = hr_image.resize((self.patch_size, self.patch_size), Image.LANCZOS)
            lr_image = lr_image.resize((self.patch_size // 4, self.patch_size // 4), Image.LANCZOS)
            
            # è½¬æ¢ä¸ºtensor
            hr_tensor = self.transform(hr_image)
            lr_tensor = self.transform(lr_image)
            
            return lr_tensor, hr_tensor
            
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾åƒå¤±è´¥ {hr_path}: {e}")
            return self._get_synthetic_data(idx)
    
    def _get_synthetic_data(self, idx):
        """ç”Ÿæˆåˆæˆæ•°æ®"""
        lr_size = self.patch_size // 4
        hr_size = self.patch_size
        
        # åˆ›å»ºæœ‰ç»“æ„çš„æ¨¡æ‹Ÿæ•°æ®
        np.random.seed(idx)  # ç¡®ä¿å¯é‡å¤æ€§
        
        # ç”ŸæˆåŸºç¡€æ¨¡å¼
        base_freq = np.random.uniform(0.1, 0.5)
        x = np.linspace(0, 2*np.pi, lr_size)
        y = np.linspace(0, 2*np.pi, lr_size)
        X, Y = np.meshgrid(x, y)
        
        # åˆ›å»ºå¤šé¢‘ç‡æ¨¡å¼
        pattern = (np.sin(base_freq * X) * np.cos(base_freq * Y) + 
                  np.sin(2 * base_freq * X) * np.cos(2 * base_freq * Y)) * 0.5 + 0.5
        
        # è½¬æ¢ä¸ºRGB
        lr_data = np.stack([pattern, pattern * 0.8, pattern * 0.6], axis=0)
        lr_tensor = torch.from_numpy(lr_data).float()
        
        # ç”Ÿæˆå¯¹åº”çš„HRå›¾åƒ
        hr_tensor = nn.functional.interpolate(
            lr_tensor.unsqueeze(0), 
            size=(hr_size, hr_size), 
            mode='bicubic', 
            align_corners=False
        ).squeeze(0)
        
        # æ·»åŠ é«˜é¢‘ç»†èŠ‚
        detail_noise = torch.randn(3, hr_size, hr_size) * 0.05
        hr_tensor = torch.clamp(hr_tensor + detail_noise, 0, 1)
        
        return lr_tensor, hr_tensor

class GPUOptimizedUNet(nn.Module):
    """GPUä¼˜åŒ–çš„U-Netæ¨¡å‹"""
    def __init__(self, in_channels=3, out_channels=3, base_channels=32):
        super().__init__()
        
        # ç¼–ç å™¨
        self.enc1 = self._make_encoder_block(in_channels, base_channels)
        self.enc2 = self._make_encoder_block(base_channels, base_channels * 2)
        self.enc3 = self._make_encoder_block(base_channels * 2, base_channels * 4)
        
        # ç“¶é¢ˆå±‚
        self.bottleneck = self._make_encoder_block(base_channels * 4, base_channels * 8)
        
        # è§£ç å™¨
        self.dec3 = self._make_decoder_block(base_channels * 8, base_channels * 4)
        self.dec2 = self._make_decoder_block(base_channels * 8, base_channels * 2)  # 8 = 4 + 4 (skip)
        self.dec1 = self._make_decoder_block(base_channels * 4, base_channels)      # 4 = 2 + 2 (skip)
        
        # è¾“å‡ºå±‚
        self.final = nn.Sequential(
            nn.Conv2d(base_channels * 2, out_channels, 1),  # 2 = 1 + 1 (skip)
            nn.Sigmoid()
        )
        
        # æ± åŒ–å’Œä¸Šé‡‡æ ·
        self.pool = nn.MaxPool2d(2)
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)
        
    def _make_encoder_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def _make_decoder_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # ä¸Šé‡‡æ ·è¾“å…¥åˆ°ç›®æ ‡å°ºå¯¸
        x = nn.functional.interpolate(x, scale_factor=4, mode='bilinear', align_corners=False)
        
        # ç¼–ç è·¯å¾„
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        
        # ç“¶é¢ˆ
        b = self.bottleneck(self.pool(e3))
        
        # è§£ç è·¯å¾„
        d3 = self.dec3(self.upsample(b))
        d3 = torch.cat([d3, e3], dim=1)
        
        d2 = self.dec2(self.upsample(d3))
        d2 = torch.cat([d2, e2], dim=1)
        
        d1 = self.dec1(self.upsample(d2))
        d1 = torch.cat([d1, e1], dim=1)
        
        # è¾“å‡º
        output = self.final(d1)
        return output

def add_diffusion_noise(image, timestep, max_timesteps=1000):
    """æ·»åŠ æ‰©æ•£å™ªå£° - GPUä¼˜åŒ–ç‰ˆæœ¬"""
    device = image.device
    
    # å™ªå£°è°ƒåº¦å‚æ•°
    beta_start = 0.0001
    beta_end = 0.02
    
    # è®¡ç®—betaå’Œalpha
    betas = torch.linspace(beta_start, beta_end, max_timesteps, device=device)
    alphas = 1.0 - betas
    alpha_cumprod = torch.cumprod(alphas, dim=0)
    
    # ç¡®ä¿timestepåœ¨æœ‰æ•ˆèŒƒå›´å†…
    timestep = torch.clamp(torch.tensor(timestep, device=device), 0, max_timesteps - 1).long()
    
    # è·å–å½“å‰æ—¶é—´æ­¥çš„alphaå€¼
    alpha_t = alpha_cumprod[timestep]
    
    # ç”Ÿæˆå™ªå£°
    noise = torch.randn_like(image)
    
    # è®¡ç®—å™ªå£°ç³»æ•°
    sqrt_alpha_t = torch.sqrt(alpha_t)
    sqrt_one_minus_alpha_t = torch.sqrt(1.0 - alpha_t)
    
    # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…å›¾åƒå¼ é‡
    while len(sqrt_alpha_t.shape) < len(image.shape):
        sqrt_alpha_t = sqrt_alpha_t.unsqueeze(-1)
        sqrt_one_minus_alpha_t = sqrt_one_minus_alpha_t.unsqueeze(-1)
    
    # æ·»åŠ å™ªå£°
    noisy_image = sqrt_alpha_t * image + sqrt_one_minus_alpha_t * noise
    
    return noisy_image, noise

def train_epoch(model, dataloader, optimizer, criterion, device, epoch, max_timesteps=1000):
    """è®­ç»ƒä¸€ä¸ªepoch - GPUä¼˜åŒ–ç‰ˆæœ¬"""
    model.train()
    total_loss = 0
    num_batches = len(dataloader)
    
    print(f"Epoch {epoch} å¼€å§‹è®­ç»ƒ...")
    
    for batch_idx, (lr_images, hr_images) in enumerate(dataloader):
        try:
            # ç§»åŠ¨æ•°æ®åˆ°GPU
            lr_images = lr_images.to(device, non_blocking=True)
            hr_images = hr_images.to(device, non_blocking=True)
            
            # éšæœºé€‰æ‹©æ—¶é—´æ­¥
            batch_size = hr_images.shape[0]
            timesteps = torch.randint(0, max_timesteps, (batch_size,), device=device)
            
            # ä¸ºæ¯ä¸ªæ ·æœ¬æ·»åŠ å™ªå£°
            noisy_hrs = []
            target_noises = []
            
            for i in range(batch_size):
                noisy_hr, noise = add_diffusion_noise(hr_images[i:i+1], timesteps[i].item(), max_timesteps)
                noisy_hrs.append(noisy_hr)
                target_noises.append(noise)
            
            noisy_hr_batch = torch.cat(noisy_hrs, dim=0)
            target_noise_batch = torch.cat(target_noises, dim=0)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            
            # æ¨¡å‹é¢„æµ‹å»å™ªåçš„å›¾åƒ
            predicted = model(lr_images)
            
            # è®¡ç®—æŸå¤±ï¼ˆé¢„æµ‹å›¾åƒä¸åŸå§‹HRå›¾åƒçš„å·®å¼‚ï¼‰
            loss = criterion(predicted, hr_images)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 10 == 0:
                print(f"  Batch {batch_idx}/{num_batches}, Loss: {loss.item():.6f}")
                
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ {batch_idx} è®­ç»ƒå¤±è´¥: {e}")
            continue
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    print(f"Epoch {epoch} å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
    return avg_loss

def main():
    print("ğŸš€ å¼€å§‹GPUä¼˜åŒ–çš„æ‰©æ•£æ¨¡å‹è®­ç»ƒ")
    print("=" * 60)
    
    # è®¾ç½®GPUå…¼å®¹æ€§
    device = setup_gpu_compatibility()
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device.type == 'cuda':
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # è®­ç»ƒé…ç½®
    config = {
        'epochs': 5,
        'batch_size': 4 if device.type == 'cuda' else 2,
        'learning_rate': 1e-4,
        'patch_size': 64,
        'max_samples': 100,
        'max_timesteps': 1000
    }
    
    print("è®­ç»ƒé…ç½®:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    # æ•°æ®è·¯å¾„
    hr_dir = "data/DIV2K_train_HR"
    lr_dir = "data/DIV2K_train_LR_bicubic/X4"
    
    # åˆ›å»ºæ•°æ®é›†
    use_real_data = os.path.exists(hr_dir) and os.path.exists(lr_dir)
    train_dataset = OptimizedSRDataset(
        hr_dir=hr_dir if use_real_data else None,
        lr_dir=lr_dir if use_real_data else None,
        patch_size=config['patch_size'],
        max_samples=config['max_samples'],
        use_real_data=use_real_data
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'], 
        shuffle=True,
        num_workers=2 if device.type == 'cuda' else 0,
        pin_memory=True if device.type == 'cuda' else False
    )
    
    print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ§  åˆ›å»ºGPUä¼˜åŒ–æ¨¡å‹...")
    model = GPUOptimizedUNet(base_channels=32).to(device)
    
    # è®¡ç®—å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)
    criterion = nn.MSELoss()
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])
    
    print(f"ä¼˜åŒ–å™¨: AdamW")
    print(f"æŸå¤±å‡½æ•°: MSE Loss")
    print(f"å­¦ä¹ ç‡è°ƒåº¦: Cosine Annealing")
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ ({config['epochs']} epochs)...")
    print("=" * 60)
    
    training_history = []
    best_loss = float('inf')
    
    try:
        for epoch in range(1, config['epochs'] + 1):
            start_time = time.time()
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss = train_epoch(
                model, train_loader, optimizer, criterion, device, epoch, config['max_timesteps']
            )
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            epoch_time = time.time() - start_time
            training_history.append(train_loss)
            
            print(f"Epoch {epoch} å®Œæˆï¼Œç”¨æ—¶: {epoch_time:.2f}ç§’ï¼Œå­¦ä¹ ç‡: {scheduler.get_last_lr()[0]:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if train_loss < best_loss:
                best_loss = train_loss
                best_model_path = "best_gpu_diffusion_model.pth"
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'config': config,
                    'epoch': epoch,
                    'loss': train_loss,
                    'training_history': training_history
                }, best_model_path)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path}")
            
            print("-" * 40)
            
        print("\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ç»ˆæŸå¤±: {training_history[-1]:.6f}")
        print(f"æœ€ä½³æŸå¤±: {best_loss:.6f}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = "final_gpu_diffusion_model.pth"
        torch.save({
            'model_state_dict': model.state_dict(),
            'config': config,
            'training_history': training_history
        }, final_model_path)
        print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
        
        # GPUå†…å­˜æ¸…ç†
        if device.type == 'cuda':
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPUå†…å­˜å·²æ¸…ç†")
        
        # ç®€å•æµ‹è¯•
        print("\nğŸ§ª è¿›è¡Œæ¨¡å‹æµ‹è¯•...")
        model.eval()
        with torch.no_grad():
            test_lr = torch.randn(1, 3, 16, 16).to(device)
            test_output = model(test_lr)
            print(f"æµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_lr.shape}")
            print(f"æµ‹è¯•è¾“å‡ºå½¢çŠ¶: {test_output.shape}")
            print("âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        # æ¸…ç†GPUå†…å­˜
        if device.type == 'cuda':
            torch.cuda.empty_cache()
    
    return model, training_history

if __name__ == "__main__":
    # å¿½ç•¥å…¼å®¹æ€§è­¦å‘Š
    warnings.filterwarnings("ignore", category=UserWarning)
    
    model, history = main()