#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰©æ•£æ¨¡å‹è¶…åˆ†è¾¨ç‡è®­ç»ƒè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨DiffusionTrainerè®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ã€‚
æ‰©æ•£æ¨¡å‹é€šè¿‡å­¦ä¹ é€æ­¥å»å™ªçš„è¿‡ç¨‹æ¥ç”Ÿæˆé«˜è´¨é‡çš„è¶…åˆ†è¾¨ç‡å›¾åƒã€‚
"""

import os
import sys
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from trainers.diffusion_trainer import DiffusionTrainer
from config.experiment_config import ExperimentConfig

def main():
    """
    ä¸»è®­ç»ƒå‡½æ•°
    """
    print("=" * 60)
    print("æ‰©æ•£æ¨¡å‹è¶…åˆ†è¾¨ç‡è®­ç»ƒ")
    print("=" * 60)
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"âœ“ CUDAå¯ç”¨ï¼Œè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        print(f"âœ“ å½“å‰è®¾å¤‡: {torch.cuda.get_device_name()}")
        device = 'cuda'
    else:
        print("âš  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        device = 'cpu'
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = project_root / "data"
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("è¯·ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶åŒ…å«è®­ç»ƒæ•°æ®")
        return
    
    print(f"âœ“ æ•°æ®ç›®å½•: {data_dir}")
    
    # é…ç½®é€‰é¡¹
    configs = {
        "åŸºç¡€é…ç½®": {
            "num_timesteps": 1000,
            "beta_start": 0.0001,
            "beta_end": 0.02,
            "noise_schedule": "linear",
            "batch_size": 4,
            "learning_rate": 1e-4,
            "num_epochs": 100,
            "accumulation_steps": 1,
            "use_mixed_precision": False,
            "gradient_clip_val": 1.0,
             "weight_decay": 1e-4,
              "num_workers": 0  # é¿å…CUDAå¤šè¿›ç¨‹é—®é¢˜
        },
        "ä¼˜åŒ–é…ç½®": {
            "num_timesteps": 1000,
            "beta_start": 0.0001,
            "beta_end": 0.02,
            "noise_schedule": "cosine",
            "batch_size": 2,  # æ‰©æ•£æ¨¡å‹å†…å­˜éœ€æ±‚è¾ƒå¤§
            "learning_rate": 1e-4,
            "num_epochs": 200,
            "accumulation_steps": 4,  # é€šè¿‡æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿæ›´å¤§çš„batch size
            "use_mixed_precision": True,
            "gradient_clip_val": 1.0,
            "weight_decay": 1e-4,
            "num_workers": 0  # é¿å…CUDAå¤šè¿›ç¨‹é—®é¢˜
        },
        "å¿«é€Ÿæµ‹è¯•": {
            "num_timesteps": 50,  # å‡å°‘æ—¶é—´æ­¥é•¿ç”¨äºå¿«é€Ÿæµ‹è¯•
            "beta_start": 0.001,
            "beta_end": 0.02,
            "noise_schedule": "linear",
            "batch_size": 1,
            "learning_rate": 1e-3,
            "num_epochs": 3,
            "accumulation_steps": 4,
            "use_mixed_precision": False,  # ç¦ç”¨æ··åˆç²¾åº¦é¿å…é—®é¢˜
            "gradient_clip_val": 1.0,
            "weight_decay": 1e-4,
            "num_workers": 0,
            "unet_channels": [16, 32]  # ä½¿ç”¨æœ€å°çš„é€šé“é…ç½®
        }
    }
    
    # è‡ªåŠ¨é€‰æ‹©å¿«é€Ÿæµ‹è¯•é…ç½®
    config_name = "å¿«é€Ÿæµ‹è¯•"
    selected_config = configs[config_name]
    print("\nğŸš€ è‡ªåŠ¨é€‰æ‹©å¿«é€Ÿæµ‹è¯•é…ç½®è¿›è¡Œè®­ç»ƒ")
    
    # åˆ›å»ºè®­ç»ƒé…ç½®
    config = ExperimentConfig()
    
    # æ›´æ–°é…ç½®å‚æ•°
    config.model_type = "diffusion"
    config.scale_factor = 4
    config.in_channels = 3
    config.out_channels = 3
    config.data_dir = str(data_dir)
    config.device = device
    
    # æ‰©æ•£æ¨¡å‹ç‰¹æœ‰å‚æ•°
    config.num_timesteps = selected_config['num_timesteps']
    config.beta_start = selected_config['beta_start']
    config.beta_end = selected_config['beta_end']
    config.noise_schedule = selected_config['noise_schedule']
    
    # è®­ç»ƒå‚æ•°
    config.batch_size = selected_config['batch_size']
    config.learning_rate = selected_config['learning_rate']
    config.epochs = selected_config['num_epochs']
    config.accumulation_steps = selected_config['accumulation_steps']
    config.use_mixed_precision = selected_config['use_mixed_precision']
    config.gradient_clip_val = selected_config['gradient_clip_val']
    config.weight_decay = selected_config['weight_decay']
    config.num_workers = selected_config['num_workers']
    
    # æ¨¡å‹æ¶æ„å‚æ•°
    if 'unet_channels' in selected_config:
        config.unet_channels = selected_config['unet_channels']
    
    # è®¾ç½®patch_sizeä»¥å‡å°‘å†…å­˜ä½¿ç”¨
    config.patch_size = 64  # ä½¿ç”¨è¾ƒå°çš„patch sizeä»¥å‡å°‘å†…å­˜ä½¿ç”¨
    
    print(f"\nè®­ç»ƒé…ç½®è¯¦æƒ…:")
    print(f"- æ¨¡å‹ç±»å‹: æ‰©æ•£æ¨¡å‹")
    print(f"- æ”¾å¤§å€æ•°: {config.scale_factor}x")
    print(f"- è¾“å…¥é€šé“: {config.in_channels}")
    print(f"- è¾“å‡ºé€šé“: {config.out_channels}")
    print(f"- æ‰©æ•£æ—¶é—´æ­¥é•¿: {config.num_timesteps}")
    print(f"- å™ªå£°è°ƒåº¦: {config.noise_schedule}")
    print(f"- BetaèŒƒå›´: [{config.beta_start}, {config.beta_end}]")
    print(f"- æ‰¹æ¬¡å¤§å°: {config.batch_size}")
    print(f"- å­¦ä¹ ç‡: {config.learning_rate}")
    print(f"- è®­ç»ƒè½®æ•°: {config.epochs}")
    print(f"- æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {config.accumulation_steps}")
    print(f"- æ··åˆç²¾åº¦è®­ç»ƒ: {config.use_mixed_precision}")
    print(f"- æ¢¯åº¦è£å‰ª: {config.gradient_clip_val}")
    print(f"- æƒé‡è¡°å‡: {config.weight_decay}")
    print(f"- æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹: {config.num_workers}")
    print(f"- è®¾å¤‡: {config.device}")
    
    try:
        # åˆå§‹åŒ–æ‰©æ•£è®­ç»ƒå™¨
        print("\nåˆå§‹åŒ–æ‰©æ•£è®­ç»ƒå™¨...")
        trainer = DiffusionTrainer(config)
        
        print("\næ¨¡å‹æ¶æ„ä¿¡æ¯:")
        total_params = sum(p.numel() for p in trainer.model.parameters())
        trainable_params = sum(p.numel() for p in trainer.model.parameters() if p.requires_grad)
        print(f"- æ€»å‚æ•°é‡: {total_params:,}")
        print(f"- å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
        
        # æ˜¾ç¤ºæ‰©æ•£æ¨¡å‹ç‰¹æœ‰ä¿¡æ¯
        print(f"\næ‰©æ•£æ¨¡å‹ä¿¡æ¯:")
        print(f"- å™ªå£°è°ƒåº¦ç±»å‹: {trainer.noise_schedule}")
        print(f"- æ—¶é—´æ­¥é•¿èŒƒå›´: [0, {trainer.num_timesteps-1}]")
        print(f"- Betaå‚æ•°èŒƒå›´: [{trainer.beta_start}, {trainer.beta_end}]")
        print(f"- å½“å‰Betaå€¼èŒƒå›´: [{trainer.betas.min():.6f}, {trainer.betas.max():.6f}]")
        
        # å¼€å§‹è®­ç»ƒ
        print("\n" + "="*60)
        print("å¼€å§‹æ‰©æ•£æ¨¡å‹è®­ç»ƒ")
        print("="*60)
        
        trainer.train()
        
        print("\n" + "="*60)
        print("è®­ç»ƒå®Œæˆï¼")
        print("="*60)
        
        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
        results_dir = Path(trainer.results_dir)
        print(f"\nè®­ç»ƒç»“æœä¿å­˜åœ¨: {results_dir}")
        print(f"- æ¨¡å‹æ£€æŸ¥ç‚¹: {results_dir / 'checkpoints'}")
        print(f"- è®­ç»ƒæ—¥å¿—: {results_dir / 'logs'}")
        
        # æ‰©æ•£æ¨¡å‹çš„ç‰¹æ®Šè¯´æ˜
        print("\næ‰©æ•£æ¨¡å‹è®­ç»ƒè¯´æ˜:")
        print("- æ‰©æ•£æ¨¡å‹é€šè¿‡å­¦ä¹ é€æ­¥å»å™ªè¿‡ç¨‹æ¥ç”Ÿæˆé«˜è´¨é‡å›¾åƒ")
        print("- è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹å­¦ä¹ é¢„æµ‹æ¯ä¸ªæ—¶é—´æ­¥çš„å™ªå£°")
        print("- æ¨ç†æ—¶é€šè¿‡å¤šæ­¥å»å™ªç”Ÿæˆæœ€ç»ˆçš„è¶…åˆ†è¾¨ç‡å›¾åƒ")
        print("- ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼Œæ‰©æ•£æ¨¡å‹èƒ½ç”Ÿæˆæ›´å¤šæ ·åŒ–å’Œé«˜è´¨é‡çš„ç»“æœ")
        
    except KeyboardInterrupt:
        print("\n\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)